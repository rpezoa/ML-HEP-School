{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "888dec98-d916-45d2-bf6a-f296cbc64bd5",
      "metadata": {
        "id": "888dec98-d916-45d2-bf6a-f296cbc64bd5"
      },
      "source": [
        "# Deep Learning for HEP events classification\n",
        "***\n",
        "* Deep learning is a subfield of machine learning that uses neural networks with multiple layers to automatically learn patterns and relationships from data, enabling tasks like image recognition, natural language processing, and more.\n",
        "* The basic unit is the artificial neuron (based in a very simple way on the biological neuron).\n",
        "* The artificial nueron receives inputs from other neurons (or the initial input), combine the information and provide output value(s).\n",
        "* Here, we will address a classification problem, using tabular data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6743c93-fc95-4f23-8ab3-afc8a0a03b01",
      "metadata": {
        "id": "b6743c93-fc95-4f23-8ab3-afc8a0a03b01"
      },
      "source": [
        "## 1. The problem\n",
        "***\n",
        "\n",
        "* Event classification is one of the most common and fundamental tasks in the field of high-energy particle physics.\n",
        "* An **event** corresponds to a proton collision generated in a particle collider, such as the Large Hadron Collider (LHC), and is represented by a set of physical properties measured by the collider's detectors.\n",
        "* We want to classify events into signal and background categories.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfab03c1-d997-4541-9fc8-b92e45089c18",
      "metadata": {
        "id": "cfab03c1-d997-4541-9fc8-b92e45089c18"
      },
      "source": [
        "## 2. Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b5bfa1-f724-47f1-a502-d9785dbac299",
      "metadata": {
        "id": "c0b5bfa1-f724-47f1-a502-d9785dbac299"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b328246-b96e-4272-a973-4eb1d299d2f3",
      "metadata": {
        "id": "3b328246-b96e-4272-a973-4eb1d299d2f3"
      },
      "source": [
        "## 3. Getting the data\n",
        "---\n",
        "* Data is obtained from this [link](https://www.openml.org/d/23512).\n",
        "* Each event is represented by a set of 28 features, including 21 low-level features corresponding to physics properties measured by the detector, and 7 high-level features derived from the previous ones.\n",
        "* Some of the event's features:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8254af2e-8332-4c13-ab6e-a2997245c4f3",
      "metadata": {
        "id": "8254af2e-8332-4c13-ab6e-a2997245c4f3"
      },
      "source": [
        "|Type| Variable  | Description   |\n",
        "|---| --- | --- |\n",
        "|low-level|lepton pT |  Momentum of the lepton|\n",
        "|low-level|lepton eta | Pseudorapidity eta of the lepton|\n",
        "|low-level|lepton phi | Azimuthal angle phi of the lepton|\n",
        "|low-level|Missing energy magnitude | Energy not detected|\n",
        "|| ... | ...|\n",
        "|high-level|m_jlv| Mass jet ($j$), lepton ($l$, electrons or muons), neutrino $\\\\nu$|\n",
        "|high-level|m_bb| Mass quarks $b$|\n",
        "|high-level|m_wbb| Mass boson $W$ and quarks $b$|\n",
        "|high-level|m_wwbb|Mass bosons $W$ and quarks $b$|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9c77fe-3d80-4ed4-a9b5-5f411eff2860",
      "metadata": {
        "id": "1c9c77fe-3d80-4ed4-a9b5-5f411eff2860"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv(\"../data/higgs_reduced.csv\")\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1z_Y3Jmp8ntiN8egwGSfZl4_D_h5qmRRl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"higgs_reduced.csv\")"
      ],
      "metadata": {
        "id": "hZAqEAVMT6Ye"
      },
      "id": "hZAqEAVMT6Ye",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f204ae6-c950-4b8e-8269-d28067dd7769",
      "metadata": {
        "id": "4f204ae6-c950-4b8e-8269-d28067dd7769"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5629eab-6b8f-4a7e-afc8-f0f76e1c6921",
      "metadata": {
        "id": "b5629eab-6b8f-4a7e-afc8-f0f76e1c6921"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38b67a8-9e76-4dfb-bd79-73b7a7c37e83",
      "metadata": {
        "id": "d38b67a8-9e76-4dfb-bd79-73b7a7c37e83"
      },
      "outputs": [],
      "source": [
        "df[\"class\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3ae895-b2ef-451f-a694-a247f740acfc",
      "metadata": {
        "id": "7b3ae895-b2ef-451f-a694-a247f740acfc"
      },
      "source": [
        "## 4. Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217f6818-066a-411d-aa6a-7556299fcfc8",
      "metadata": {
        "id": "217f6818-066a-411d-aa6a-7556299fcfc8"
      },
      "outputs": [],
      "source": [
        "def show_null(df):\n",
        "    total = df.isnull().sum().sort_values(ascending=False)\n",
        "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
        "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    display(missing_data)\n",
        "show_null(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will simply delete the rows with missing values. However, you can use more sophisticated techniques to perform data imputation."
      ],
      "metadata": {
        "id": "LNK2Ei96YVSD"
      },
      "id": "LNK2Ei96YVSD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8785c5fc-e327-4255-ad3f-aa9ccd6cae3c",
      "metadata": {
        "id": "8785c5fc-e327-4255-ad3f-aa9ccd6cae3c"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f315c00-da02-46bc-a2a9-c569d492961a",
      "metadata": {
        "id": "8f315c00-da02-46bc-a2a9-c569d492961a"
      },
      "source": [
        "## 5. Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a955228-1a16-4789-af4b-4330cce42945",
      "metadata": {
        "id": "1a955228-1a16-4789-af4b-4330cce42945"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap='BrBG', annot = True, fmt=\".2f\", annot_kws={\"size\":7})\n",
        "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':8}, pad=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3a36fe-90bb-4f06-8ed8-ad1dd0e0e825",
      "metadata": {
        "id": "0b3a36fe-90bb-4f06-8ed8-ad1dd0e0e825"
      },
      "source": [
        "## 6. Pair plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e3ac7c-37cd-427e-8f58-6d8050b46d3b",
      "metadata": {
        "id": "12e3ac7c-37cd-427e-8f58-6d8050b46d3b"
      },
      "outputs": [],
      "source": [
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "sns.pairplot(df,vars = ['lepton_pT','lepton_eta','lepton_phi'], hue=\"class\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5bd2a7-7649-49cf-ae1d-b6277134a26e",
      "metadata": {
        "id": "6b5bd2a7-7649-49cf-ae1d-b6277134a26e"
      },
      "source": [
        "## 7. Generating training, validation and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd616dcb-4dd1-492d-aa56-34e570fdf8d3",
      "metadata": {
        "id": "fd616dcb-4dd1-492d-aa56-34e570fdf8d3"
      },
      "outputs": [],
      "source": [
        "y = df[\"class\"]\n",
        "y = y.astype(int)\n",
        "X = df.iloc[:,2:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2addf3a7-a033-422f-b8c5-85fe89186809",
      "metadata": {
        "id": "2addf3a7-a033-422f-b8c5-85fe89186809"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb50a6c6-e6ab-4476-933d-2ebf840ab2e0",
      "metadata": {
        "id": "bb50a6c6-e6ab-4476-933d-2ebf840ab2e0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
        "                                test_size=0.3, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,\n",
        "                                                  test_size=0.2, random_state=0)\n",
        "n_classes = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9673ea8-b4f4-4a44-9c2d-e05cb14e7377",
      "metadata": {
        "id": "a9673ea8-b4f4-4a44-9c2d-e05cb14e7377"
      },
      "source": [
        "## 8. Building a FFNN using Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa3dde9-4253-4e2e-8b37-a39b15cf2a08",
      "metadata": {
        "id": "cfa3dde9-4253-4e2e-8b37-a39b15cf2a08"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow  as tf\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(300, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(150, activation = \"relu\"))\n",
        "model.add(Dense(100, activation = \"relu\"))\n",
        "model.add(Dense(50, activation = \"relu\"))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce07e482-34c4-4c01-b43e-ab96ab37c212",
      "metadata": {
        "scrolled": true,
        "id": "ce07e482-34c4-4c01-b43e-ab96ab37c212"
      },
      "outputs": [],
      "source": [
        "metrics_m = [\n",
        "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
        "    tf.keras.metrics.Precision(name=\"precision\"),\n",
        "    tf.keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(optimizer=SGD(),\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Performance metrics"
      ],
      "metadata": {
        "id": "WhTiNZ78ZGWT"
      },
      "id": "WhTiNZ78ZGWT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e71feb-a5a5-4ce4-91f9-c0d3bfc3ac00",
      "metadata": {
        "id": "41e71feb-a5a5-4ce4-91f9-c0d3bfc3ac00"
      },
      "outputs": [],
      "source": [
        "def show_history(history):\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    plt.figure()\n",
        "    plt.plot(train_loss,'r', label=\"train\")\n",
        "    plt.plot(val_loss,'g', label=\"validation\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_metrics(y_pred,th):\n",
        "    cm = confusion_matrix(y_test, y_pred>th)\n",
        "    print(cm)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraud\", \"Fraud\"])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "    d = classification_report(y_test, y_pred > th,output_dict=True)\n",
        "    display(pd.DataFrame.from_dict(d))\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6659082-f143-439e-a1ac-6491ec38ee2f",
      "metadata": {
        "id": "b6659082-f143-439e-a1ac-6491ec38ee2f"
      },
      "outputs": [],
      "source": [
        "show_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe22758-4ec6-4b80-8774-0f5cf2a96641",
      "metadata": {
        "id": "3fe22758-4ec6-4b80-8774-0f5cf2a96641"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = y_pred_prob >= 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee6d9e5-e880-42ca-bac6-3f5ef9c11960",
      "metadata": {
        "id": "5ee6d9e5-e880-42ca-bac6-3f5ef9c11960"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "\n",
        "fpr, tpr, ths = roc_curve(y_test,  y_pred)\n",
        "auc_ = auc(fpr, tpr)\n",
        "f1 = f1_score(y_test,  (y_pred>.5))\n",
        "prec = precision_score(y_test,  (y_pred>.5))\n",
        "rec = recall_score(y_test,  (y_pred>.5))\n",
        "acc = accuracy_score(y_test,  (y_pred>.5))\n",
        "print(\"F1: %.2f\" %f1 , \" -- prec: %.2f\" %prec, \" -- recall: %.2f\" %rec, \" -- acc: %.2f\" %acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8c21708-9842-4adf-82b5-b728a8cd336d",
      "metadata": {
        "id": "f8c21708-9842-4adf-82b5-b728a8cd336d"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              )\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e8452d-6932-4570-894f-04136226a6b6",
      "metadata": {
        "id": "f3e8452d-6932-4570-894f-04136226a6b6"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr,tpr, label='ROC curve (area = %.2f)' %auc_)\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d8767c-9b9e-4c4f-8a2e-58df6f118ca0",
      "metadata": {
        "id": "99d8767c-9b9e-4c4f-8a2e-58df6f118ca0"
      },
      "outputs": [],
      "source": [
        "d = classification_report(y_test, y_pred,output_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42f31ac-cee4-490b-85f2-f963a84259b6",
      "metadata": {
        "id": "e42f31ac-cee4-490b-85f2-f963a84259b6"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame.from_dict(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. ANN Score plot\n",
        "***\n",
        "Histogram of the ANN scores in the testing set"
      ],
      "metadata": {
        "id": "zD1go1-vZTPz"
      },
      "id": "zD1go1-vZTPz"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install mplhep"
      ],
      "metadata": {
        "id": "aKROCU64XOi4"
      },
      "id": "aKROCU64XOi4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125ab7fd-f287-426e-af7c-5c1957d93388",
      "metadata": {
        "id": "125ab7fd-f287-426e-af7c-5c1957d93388"
      },
      "outputs": [],
      "source": [
        "import mplhep as hep\n",
        "# Score distribution\n",
        "f, axs = plt.subplots(1, 1, sharex=True, sharey=True)\n",
        "h_sig_test, bins_sig_test = np.histogram(y_pred_prob[y_test == 1], bins=30)\n",
        "h_back_test, bins_back_test = np.histogram(y_pred_prob[y_test == 0], bins=30)\n",
        "axs.set_title(\"ANN Classifier\")\n",
        "hep.histplot([h_sig_test, h_back_test], bins_sig_test, ax=axs,label=[\"Test-S\", \"Test-B\"])\n",
        "axs.legend()\n",
        "axs.set_xlabel(\"Score\")\n",
        "axs.set_ylabel(\"Number of Events\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565babac-dc1c-4c7e-856a-ae01eee1a9ca",
      "metadata": {
        "id": "565babac-dc1c-4c7e-856a-ae01eee1a9ca"
      },
      "source": [
        "## 11. Using keras_tuner\n",
        "****\n",
        " * To find the best hyperparameters for their machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install keras-tuner"
      ],
      "metadata": {
        "id": "daGhqsxkUm_F"
      },
      "id": "daGhqsxkUm_F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2669ad9-dac2-4a7e-9086-eea35d700836",
      "metadata": {
        "id": "d2669ad9-dac2-4a7e-9086-eea35d700836"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90aeb9f2-0387-45d7-a8e3-317537ee1e1d",
      "metadata": {
        "id": "90aeb9f2-0387-45d7-a8e3-317537ee1e1d"
      },
      "outputs": [],
      "source": [
        "# Define the model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input Layer\n",
        "    model.add(Dense(hp.Int('units_input', min_value=50, max_value=300, step=50),\n",
        "                    input_shape=(X_train.shape[1],), activation='relu'))\n",
        "\n",
        "    # Hidden Layers\n",
        "    for i in range(hp.Int('num_hidden_layers', 1, 4)):\n",
        "        model.add(Dense(hp.Int(f'units_{i}', min_value=50, max_value=300, step=50),\n",
        "                        activation='relu'))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16cce88-1caa-47b2-b1d8-a30c320e9c5b",
      "metadata": {
        "scrolled": true,
        "id": "a16cce88-1caa-47b2-b1d8-a30c320e9c5b"
      },
      "outputs": [],
      "source": [
        "# Instantiate the RandomSearch tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  # Number of models to try\n",
        "    executions_per_trial=2,  # Number of times to train each model\n",
        "    directory='my_dir',  # Directory to save the tuner results\n",
        "    project_name='random_search_example'\n",
        ")\n",
        "\n",
        "# Search for the best model\n",
        "tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2173cc-bb8b-4ed6-9afd-9426a7632c0a",
      "metadata": {
        "id": "7c2173cc-bb8b-4ed6-9afd-9426a7632c0a"
      },
      "outputs": [],
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best hyperparameters:\\n\")\n",
        "print(f\"Input Layer Units: {best_hps.get('units_input')}\")\n",
        "for i in range(best_hps.get('num_hidden_layers')):\n",
        "    print(f\"Hidden Layer {i+1} Units: {best_hps.get(f'units_{i}')}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Build and train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_accuracy = best_model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba5823c-c242-48e6-a448-e2ab5db1a62a",
      "metadata": {
        "id": "8ba5823c-c242-48e6-a448-e2ab5db1a62a"
      },
      "outputs": [],
      "source": [
        "y_pred_prob_2 = best_model.predict(X_test)\n",
        "y_pred_2 = y_pred_prob_2 >= 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VhOQeSMRaW5b"
      },
      "id": "VhOQeSMRaW5b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Task</b>\n",
        "\n",
        "<ul>\n",
        "  <li>Display the performance metrics, confusion matrix, and ANN output (scores) of the best model.</li>\n",
        "  <li>Modify the tuner to improve the classification performance.</li>\n",
        "</ul>\n",
        "    \n",
        "    \n",
        "</div>"
      ],
      "metadata": {
        "id": "vwmCU2Rfacu5"
      },
      "id": "vwmCU2Rfacu5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atj73J67au2V"
      },
      "id": "atj73J67au2V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}